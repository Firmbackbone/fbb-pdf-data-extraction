{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Initial Text Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using PyMuPDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz  # Import the PyMuPDF library\n",
    "\n",
    "def extract_text_pymupdf(pdf_path):\n",
    "    doc = fitz.open(pdf_path)  # Open the PDF file\n",
    "    text = \"\"  # Initialize an empty string to store text\n",
    "\n",
    "    for page in doc:  # Iterate through each page\n",
    "        text += page.get_text()  # Extract text from the page and append it\n",
    "\n",
    "    doc.close()  # Close the document\n",
    "    return text\n",
    "\n",
    "# here change path to pdf\n",
    "#df_path = '/Users/juliamarkusiewicz/Documents/research assistant work code/PDF_Mining_Julia/Jaarrekening-2022-DG-Press-HoldinG-B.V.pdf'\n",
    "pdf_path = '/Users/juliamarkusiewicz/Documents/research assistant work code/PDF_Mining_Julia/Jaarrekening-Momo-Medical-Holding-B.V.-2022.pdf'\n",
    "#pdf_path = '/Users/juliamarkusiewicz/Documents/research assistant work code/PDF_Mining_Julia/Jaarrekening-2022-Informed-IT-Holding-B.V.pdf'\n",
    "raw_text = extract_text_pymupdf(pdf_path)\n",
    "text = extract_text_pymupdf(pdf_path)\n",
    "text_data = extract_text_pymupdf(pdf_path)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using PyPDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyPDF2\n",
    "\n",
    "def extract_text_pypdf2(pdf_path):\n",
    "    text = \"\"  # Initialize an empty string to store text\n",
    "    with open(pdf_path, 'rb') as file:  # Open the PDF file in binary mode\n",
    "        reader = PyPDF2.PdfReader(file)  # Create a PDF reader object\n",
    "\n",
    "        for page in reader.pages:  # Iterate through each page\n",
    "            text += page.extract_text() + \"\\n\"  # Extract text and append it\n",
    "\n",
    "    return text\n",
    "\n",
    "# Example usage\n",
    "pdf_path = '/Users/juliamarkusiewicz/Documents/research assistant work code/PDF_Mining_Julia/Jaarrekening-2022-DG-Press-HoldinG-B.V.pdf'\n",
    "text = extract_text_pypdf2(pdf_path)\n",
    "raw_text=extract_text_pypdf2(pdf_path)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tabula import read_pdf\n",
    "\n",
    "def extract_tables_tabula(pdf_path):\n",
    "    # This function returns a list of DataFrames, one for each page\n",
    "    dfs = read_pdf(pdf_path, pages='all', multiple_tables=True)\n",
    "\n",
    "    for i, df in enumerate(dfs):\n",
    "        print(f\"Table {i+1}:\")\n",
    "        print(df)  # Print each table\n",
    "        # You can also save the DataFrame to a CSV or Excel\n",
    "        # df.to_csv(f'table_{i+1}.csv') # Uncomment to save to CSV\n",
    "\n",
    "# Example usage\n",
    "pdf_path = '/Users/juliamarkusiewicz/Documents/research assistant work code/PDF_Mining_Julia/Jaarrekening-2022-DG-Press-HoldinG-B.V.pdf'\n",
    "extract_tables_tabula(pdf_path)\n",
    "text = extract_tables_tabula(pdf_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Extracting, Categorising, and Processing data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#correct\n",
    "\n",
    "MAX_DESCRIPTION_LENGTH = 180\n",
    "LLM_length=100\n",
    "\n",
    "# is_number returns a number stripped from commas, dots and parentheses and a boolean indicating if the input is a number\n",
    "# or the raw data if `s` is not a number\n",
    "def is_number(s: str) -> [str, bool]:\n",
    "    if s.startswith(\"(\") and s.endswith(\")\"):\n",
    "        s = s[1:-1]\n",
    "    elif s == \"-\":\n",
    "        return 0, True\n",
    "    # NOTE: more cases here\n",
    "    num = s.replace(\",\", \"\").replace(\".\", \"\")\n",
    "    return num, num.isdigit()\n",
    "\n",
    "def is_year(s) -> bool: return 1900 <= int(s) <= 2100\n",
    "def ends_with_percent(s: str) -> bool: return s.endswith(\"%\")\n",
    "\n",
    "def is_page_number(s: str) -> bool:\n",
    "    return s.strip().startswith(\"Page\") or s.strip().startswith(\"Pagina\") \n",
    "\n",
    "def parse_adjusted_financial_text(text):\n",
    "    # Split the text into lines\n",
    "    lines = text.strip().split(\"\\n\")\n",
    "    \n",
    "    # Initialize an empty list to store our parsed data\n",
    "    parsed_data = []\n",
    "    \n",
    "    # this variable tracks if we found any numeric data on the current page\n",
    "    no_numeric_data_on_page = True\n",
    "    misc_text_data = []\n",
    "    \n",
    "    # Initialize empty strings for current description and values\n",
    "    current_description = \"\"\n",
    "    value_year1 = \"\"\n",
    "    \n",
    "    # Iterate over each line in the text\n",
    "    for line in lines:\n",
    "        # Check if line is a description or a value\n",
    "        maybe_num, is_num = is_number(line)\n",
    "        \n",
    "        if is_num and is_year(maybe_num):\n",
    "            continue\n",
    "        elif ends_with_percent(line):\n",
    "            continue\n",
    "        \n",
    "        if is_num:\n",
    "            # If it's a digit, it's a value\n",
    "            if value_year1 == \"\":\n",
    "                # If the first value is not yet set, set it as year1 value\n",
    "                value_year1 = maybe_num\n",
    "            else:\n",
    "                print([current_description.strip().lower(), int(value_year1), int(maybe_num)])\n",
    "                parsed_data.append([current_description.strip().lower(), int(value_year1), int(maybe_num)])\n",
    "                # Reset the values for the next set of data\n",
    "                current_description = \"\"\n",
    "                value_year1 = \"\"\n",
    "                no_numeric_data_on_page = False\n",
    "        else:\n",
    "            # we might find long streches of text unrelated to data labeling\n",
    "            # in that case we have the following solutions:\n",
    "            #  * cap descripiton length (x chars)\n",
    "            #  * try to extract category name using llms\n",
    "            # If it's not a digit, it's a description\n",
    "            # Accumulate descriptions until we reach a digit\n",
    "            if current_description:\n",
    "                if is_page_number(line):\n",
    "                    if no_numeric_data_on_page:\n",
    "                        misc_text_data.append(current_description)\n",
    "                        current_description = \"\"\n",
    "                    # we want to reset the tracker at every new page\n",
    "                    no_numeric_data_on_page = True\n",
    "                else: current_description += \" \" + line.strip()\n",
    "               \n",
    "                #skip if the length is more than MAX_DESCRIPTION_LENGTH\n",
    "                if len(current_description) > MAX_DESCRIPTION_LENGTH:\n",
    "                    current_description = \"\"        \n",
    "            else:\n",
    "                current_description = line\n",
    "                \n",
    "    # Convert the parsed data into a DataFrame\n",
    "    return pd.DataFrame(parsed_data, columns=['Description', 'Year 1 EUR', 'Year 2 EUR']), misc_text_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse the adjusted text data\n",
    "df_parsed, misc_text_data = parse_adjusted_financial_text(text_data)\n",
    "\n",
    "# Display the parsed DataFrame\n",
    "display(df_parsed)\n",
    "#print(df_parsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: different way to extract information, using also last :500 characters didn't work\n",
    "# extracting company information\n",
    "client = OpenAI(base_url = 'http://localhost:11434/v1',api_key='ollama')\n",
    "\n",
    "def prepare_prompt(text: str) -> list:\n",
    "    return [\n",
    "        # prompt not final, to be adjusted\n",
    "        {\"role\": \"system\", \"content\": \" extract the name of the company, the two years that the financial statement is about (i.e 2021, 2022), in the order they appear, the currency, and the type of financial statement. Output 5 (not more) variables, separated by commas.\"},\n",
    "        {\"role\": \"user\", \"content\": text},\n",
    "        {\"role\": \"assistant\", \"content\": \"category name:\"}\n",
    "    ]\n",
    "\n",
    "\n",
    "def output_company_information(text: str) -> str:\n",
    "    messages = prepare_prompt(text)\n",
    "    response = client.chat.completions.create(\n",
    "        # TODO: try on smaller models\n",
    "        model=\"gemma:7b\",\n",
    "        messages = messages,\n",
    "        temperature=0.4\n",
    "    )\n",
    "  \n",
    "    company_information = response.choices[0].message.content\n",
    "    return company_information\n",
    "\n",
    "# from the first 500 characters of df_parsed, extract company name, year, currency, and the type of financial statement\n",
    "company_information = output_company_information(text[:500])\n",
    "#make company informarion only the first row of the output\n",
    "company_information = company_information.split(\"\\n\")[0]\n",
    "print(company_information)\n",
    "\n",
    "\n",
    "# make a new dataframe with the extracted company information\n",
    "company_information = company_information.split(\",\")\n",
    "company_information_df = pd.DataFrame([company_information], columns=['Company Name', 'Year 1', 'Year 2', 'Currency', 'Type of Financial Statement'])\n",
    "display(company_information_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup for replacing all outputs longer than XXX characters with a category name extracted by gemma\n",
    "\n",
    "def prepare_messages(text: str) -> list:\n",
    "    return [\n",
    "        # prompt not final, to be adjusted\n",
    "        {\"role\": \"system\", \"content\": \"This is a fragment of description from a financial statement. Extract a financial category name from the description. Output only the category and no other text or explanations. If there is no category or not applicable, output only: -.\"},\n",
    "        {\"role\": \"user\", \"content\": text},\n",
    "        {\"role\": \"assistant\", \"content\": \"category name:\"}\n",
    "    ]\n",
    "\n",
    "def output_category_name(text: str) -> str:\n",
    "    messages = prepare_messages(text)\n",
    "    response = client.chat.completions.create(\n",
    "        # TODO: try on smaller models\n",
    "        model=\"gemma:7b\",\n",
    "        messages = messages,\n",
    "        temperature=1\n",
    "    )\n",
    "    category_name = response.choices[0].message.content\n",
    "     # convert to lowercase\n",
    "    category_name = category_name.lower()\n",
    "    # remove whitespaces\n",
    "    category_name = category_name.strip()\n",
    "    return category_name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change the 'Year 1 EUR' and 'Year 2 EUR' columns in df_parsed to the values under Year 1 and Year 2 in company_information_df\n",
    "df_parsed = df_parsed.rename(columns={'Year 1 EUR': company_information_df['Year 1'][0], 'Year 2 EUR': company_information_df['Year 2'][0]})\n",
    "df_parsed['Category'] = df_parsed['Description']\n",
    "\n",
    "# extracring category names for descriptions longer than LLM_length\n",
    "for i, row in enumerate(df_parsed['Description']):\n",
    "    if len(row) > LLM_length and len(row) < MAX_DESCRIPTION_LENGTH:\n",
    "        category_name = output_category_name(row)\n",
    "        # tentative solution, to be deleted once the prompt is adjusted\n",
    "        category_name = category_name.split(\"\\n\")[0]\n",
    "        df_parsed.at[i, 'Category'] = category_name\n",
    "        print(row, \"->\", category_name)\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df_parsed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mapping data to ledger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from financial_ledger import financial_ledger as ledger\n",
    "import jellyfish as jf\n",
    "from jellyfish import jaro_winkler_similarity as jws\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ledger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: add description of Jaro-Winkler similarity\n",
    "\n",
    "def add_matching_info_to_df(df, ledger):\n",
    "    # Initialize lists to hold match results\n",
    "    best_matches = []\n",
    "    match_scores = []\n",
    "    \n",
    "    for index, row in df.iterrows():\n",
    "        description = row['Description'].lower()\n",
    "        max_score = 0\n",
    "        best_match = \"\"\n",
    "        for key, ledger_entry in ledger.items():\n",
    "            # Iterate through both 'English' and 'Dutch' lists if they exist\n",
    "            for lang in ['English', 'Dutch']:\n",
    "                if lang in ledger_entry:  # Check if the language key exists\n",
    "                    for term in ledger_entry[lang]:\n",
    "                        score = jf.jaro_winkler(description, term.lower())\n",
    "                        if score > max_score:\n",
    "                            max_score = score\n",
    "                            best_match = key\n",
    "        # Append match result or indicate no match found\n",
    "        if max_score > 0.7:\n",
    "            best_matches.append(best_match)\n",
    "            match_scores.append(max_score)\n",
    "        else:\n",
    "            best_matches.append(\"No match found\")\n",
    "            match_scores.append(max_score)\n",
    "    \n",
    "    # Add the match results to the DataFrame\n",
    "    df['Best Match_JW'] = best_matches\n",
    "    df['Match Score_JW'] = match_scores\n",
    "\n",
    "add_matching_info_to_df(df_parsed, ledger)\n",
    "\n",
    "# Now df_parsed contains two new columns: 'Best Match' and 'Match Score'\n",
    "display(df_parsed)\n",
    "\n",
    "#display only the rows with no match found\n",
    "# df_no_match = df_parsed[df_parsed['Best Match_JW'] == \"No match found\"]\n",
    "# display(df_no_match)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is used to display all rows in the dataframe when checking output, not necessary to run as it makes the output very long, mostly for testing purposes\n",
    "\n",
    "pd.set_option('display.max_rows', None)  # Show all rows\n",
    "pd.set_option('display.max_columns', None)  # Show all columns\n",
    "pd.set_option('display.width', None)  # Auto-detect the display width\n",
    "pd.set_option('display.max_colwidth', -1)  # Display full width of columns\n",
    "\n",
    "display(df_parsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing cosine similarity\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Combine all texts to build the vocabulary for vectorization\n",
    "all_texts = list(df_parsed['Category']) + [item for sublist in ledger.values() for lang in sublist if lang in ['English', 'Dutch'] for item in sublist[lang]]\n",
    "\n",
    "vectorizer = TfidfVectorizer().fit(all_texts)\n",
    "description_vectors = vectorizer.transform(df_parsed['Category'])\n",
    "\n",
    "# Prepare and vectorize ledger entries\n",
    "ledger_entries = [item for sublist in ledger.values() for lang in sublist if lang in ['English', 'Dutch'] for item in sublist[lang]]\n",
    "ledger_vectors = vectorizer.transform(ledger_entries)\n",
    "\n",
    "# Calculate cosine similarity between description vectors and ledger vectors\n",
    "similarity_scores = cosine_similarity(description_vectors, ledger_vectors)\n",
    "\n",
    "# Determine the best match for each description based on the highest cosine similarity score\n",
    "best_matches = [ledger_entries[np.argmax(row)] if max(row) > 0.7 else \"No match found\" for row in similarity_scores]\n",
    "df_parsed['Best Match_Cosine'] = best_matches\n",
    "df_parsed['Highest Match Score_Cosine'] = [max(row) for row in similarity_scores]\n",
    "display(df_parsed)\n",
    "\n",
    "# Display a summary of match scores to help decide on a threshold\n",
    "#print(df_parsed[['Description', 'Best Match', 'Highest Match Score']].head(20))\n",
    "# Adjust threshold based on inspection\n",
    "#threshold = 0.7\n",
    "#df_parsed['Best Match Adjusted'] = [ledger_entries[np.argmax(row)] if max(row) > threshold else \"No match found\" for row in similarity_scores]\n",
    "\n",
    "# Review adjustments\n",
    "#display(df_parsed[['Category', 'Best Match Adjusted', 'Highest Match Score']])\n",
    "\n",
    "# output only the rows where the best match is not found\n",
    "#no_match_found = df_parsed[df_parsed['Best Match Adjusted'] == 'No match found']\n",
    "#display(no_match_found)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Creating output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if in df_parsed, best match JR and best match cosine  = \"not found\" or \"not applicable\", delete the row\n",
    "# TODO: check if when there is no match from one method, if there is one from the other \n",
    "\n",
    "df_parsed = df_parsed[df_parsed['Best Match_JW'] != \"No match found\"]\n",
    "df_parsed = df_parsed[df_parsed['Best Match_Cosine'] != \"No match found\"]\n",
    "df_parsed = df_parsed[df_parsed['Best Match_JW'] != \"not applicable\"]\n",
    "df_parsed = df_parsed[df_parsed['Best Match_Cosine'] != \"not applicable\"]\n",
    "\n",
    "# if categories are found, make a new df with catgegory name, year 1 value,  year 2 value, output info from the ledger like id and other categories based on best match\n",
    "df_output = df_parsed[['Category', company_information_df['Year 1'][0], company_information_df['Year 2'][0], 'Best Match_JW', 'Match Score_JW', 'Best Match_Cosine', 'Highest Match Score_Cosine']]\n",
    "\n",
    "# based on the best match in the ledger, make new columns with balance, id, category, and statement type from the ledger for each row in df_output\n",
    "def add_ledger_info_to_df(df, ledger):\n",
    "    # Initialize lists to hold match results\n",
    "    balance = []\n",
    "    id = []\n",
    "    category = []\n",
    "    statement_type = []\n",
    "    postencode= []\n",
    "     \n",
    "    for index, row in df.iterrows():\n",
    "        best_match = row['Best Match_JW']\n",
    "        for key, ledger_entry in ledger.items():\n",
    "            if key == best_match:\n",
    "                balance.append(ledger_entry['balance'])\n",
    "                id.append(ledger_entry['id'])\n",
    "                category.append(ledger_entry['category'])\n",
    "                statement_type.append(ledger_entry['statement_type'])\n",
    "                postencode.append(ledger_entry['postencode'])\n",
    "    \n",
    "    # Add the match results to the DataFrame\n",
    "    df_output['Balance'] = balance\n",
    "    df_output['ID'] = id\n",
    "    df_output['Category'] = category\n",
    "    df_output['Statement Type'] = statement_type\n",
    "    df_output['Postencode'] = postencode\n",
    "\n",
    "add_ledger_info_to_df(df_output, ledger)\n",
    "display(df_output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data Cleaning , Classifying "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifying Data \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_table(df):\n",
    "    # Example of simple keyword-based classification\n",
    "    if 'Total of inventories' in df.columns:\n",
    "        return 'Inventory'\n",
    "    elif 'Total of non-current assets' in df.columns:\n",
    "        return 'Non-Current Assets'\n",
    "\n",
    "\n",
    "    else:\n",
    "        return 'Unknown'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data Validation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Consistency check ...\n",
    "\n",
    "# Balance sheet validation rule: Assets = Liabilities + Equity\n",
    "if total_assets == total_liabilities + equity:\n",
    "    print(\"The balance sheet balances.\")\n",
    "else:\n",
    "    print(\"There is a discrepancy in the balance sheet.\")\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
